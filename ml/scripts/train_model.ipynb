{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import typing as tp\n",
    "import pandas as pd\n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "dataset_path: str = \"/Users/chrnegor/Documents/study/UrTraining/ml/scripts/data/dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "train_df = df.sample(frac=0.8)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/zrjm4hxd2752djqdmtnnvk700000gn/T/ipykernel_56644/3085943356.py:9: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  if abs(int(negative_item['course_id']) - int(row['course_id'])) > 3:\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    query: str = row['user_profile_w_meta']\n",
    "    positive: str = row['course_description']\n",
    "    negatives: tp.List[str] = []\n",
    "    while len(negatives) < 4:\n",
    "        negative_item = df.sample(1)\n",
    "        if abs(int(negative_item['course_id']) - int(row['course_id'])) > 3:\n",
    "            negatives.append(negative_item['course_description'])\n",
    "    \n",
    "    for negative in negatives:\n",
    "        training_data.append({\n",
    "            'query': query,\n",
    "            'positive': positive,\n",
    "            'negative': negative\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.DataFrame(training_data, columns=['query', 'positive', 'negative'])\n",
    "training_data.to_csv(\"data/training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model_id: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "dataset_path: str = \"data/training_data.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(texts=[row['query'], row['positive'], row['negative']])\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "train_loss = losses.TripletLoss(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Metrics before training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prepare_documents(raw_docs: tp.List[tp.Dict[str, tp.Any]]) -> tp.List[str]:\n",
    "    docs: tp.List[str] = []\n",
    "    for doc in raw_docs:\n",
    "        formatted_doc = \"\\n\".join([f\"{k}: {str(v)}\" for k, v in doc.items()])\n",
    "        docs.append(formatted_doc)\n",
    "    return docs\n",
    "\n",
    "course_descriptions: tp.List[tp.Dict[str, tp.Any]] = json.load(\n",
    "    open(\"data/200_sport_programs.json\")\n",
    ")\n",
    "\n",
    "documents = prepare_documents(course_descriptions)\n",
    "\n",
    "model = SentenceTransformer(model_id)\n",
    "docs_embeddings = model.encode(documents)\n",
    "query_embeddings = model.encode(test_df['user_profile_w_meta'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics before training:\n",
      "Hit Rate@10: 0.0000\n",
      "Recall@10: 0.0000\n",
      "Precision@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(query_embeddings, docs_embeddings, test_df, k=10):\n",
    "    \"\"\"Calculate hit rate, recall, and precision at k\"\"\"\n",
    "    similarities = cosine_similarity(query_embeddings, docs_embeddings)\n",
    "    \n",
    "    hit_rate = 0\n",
    "    total_recall = 0\n",
    "    total_precision = 0\n",
    "    \n",
    "    for i, (_, row) in enumerate(test_df.iterrows()):\n",
    "        query_similarities = similarities[i]\n",
    "        top_k_indices = np.argsort(query_similarities)[::-1][:k]\n",
    "        positive_course_id = int(row['course_id'])\n",
    "        \n",
    "        if positive_course_id in top_k_indices:\n",
    "            hit_rate += 1\n",
    "            \n",
    "        relevant_in_topk = 1 if positive_course_id in top_k_indices else 0\n",
    "        total_relevant = 1 \n",
    "        \n",
    "        recall = relevant_in_topk / total_relevant\n",
    "        precision = relevant_in_topk / k\n",
    "        \n",
    "        total_recall += recall\n",
    "        total_precision += precision\n",
    "    \n",
    "    num_queries = len(test_df)\n",
    "    hit_rate = hit_rate / num_queries\n",
    "    avg_recall = total_recall / num_queries\n",
    "    avg_precision = total_precision / num_queries\n",
    "    \n",
    "    return hit_rate, avg_recall, avg_precision\n",
    "\n",
    "hit_rate_before, recall_before, precision_before = calculate_metrics(\n",
    "    query_embeddings, docs_embeddings, test_df\n",
    ")\n",
    "\n",
    "print(f\"Metrics before training:\")\n",
    "print(f\"Hit Rate@10: {hit_rate_before:.4f}\")\n",
    "print(f\"Recall@10: {recall_before:.4f}\")\n",
    "print(f\"Precision@10: {precision_before:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 09:40, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.076800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=25,\n",
    "    warmup_steps=10,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "trained_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_embeddings = trained_model.encode(documents)\n",
    "query_embeddings = trained_model.encode(test_df['user_profile_w_meta'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics after training:\n",
      "Hit Rate@10: 0.0870\n",
      "Recall@10: 0.0870\n",
      "Precision@10: 0.0087\n"
     ]
    }
   ],
   "source": [
    "hit_rate_after, recall_after, precision_after = calculate_metrics(\n",
    "    query_embeddings, docs_embeddings, test_df\n",
    ")\n",
    "\n",
    "print(f\"Metrics after training:\")\n",
    "print(f\"Hit Rate@10: {hit_rate_after:.4f}\")\n",
    "print(f\"Recall@10: {recall_after:.4f}\")\n",
    "print(f\"Precision@10: {precision_after:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics Improvements:\n",
      "Hit Rate@10 improved by: 0.0870\n",
      "Recall@10 improved by: 0.0870\n",
      "Precision@10 improved by: 0.0087\n"
     ]
    }
   ],
   "source": [
    "hit_rate_improvement = hit_rate_after - hit_rate_before\n",
    "recall_improvement = recall_after - recall_before\n",
    "precision_improvement = precision_after - precision_before\n",
    "\n",
    "print(f\"\\nMetrics Improvements:\")\n",
    "print(f\"Hit Rate@10 improved by: {hit_rate_improvement:.4f}\")\n",
    "print(f\"Recall@10 improved by: {recall_improvement:.4f}\")\n",
    "print(f\"Precision@10 improved by: {precision_improvement:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
